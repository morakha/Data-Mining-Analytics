{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Rakha_Mohamed_Lab2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTtjzb-C8WfV",
        "colab_type": "text"
      },
      "source": [
        "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`, as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84YmnDPm8WfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME = \"Mohamed Rakha\""
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPzgt7538Wfe",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "421e2e076e4bd859041d2c49e8c1b374",
          "grade": false,
          "grade_id": "cell-9ca594c076da14a9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "a84b7eS58Wff",
        "colab_type": "text"
      },
      "source": [
        "# Lab 2: Clustering ##\n",
        "\n",
        "**Please read the following instructions very carefully**\n",
        "\n",
        "## About the Dataset\n",
        "The dataset for this lab has been created from some custom features from Lab 1. The columns are named as q1, q2....etc. A description of the features can be found at this link: https://docs.google.com/spreadsheets/d/18wwyjGku2HYfgDX9Vez64lGHz31E_PfbpmAdfb7ly6M/edit?usp=sharing\n",
        "\n",
        "## Working on the assignment / FAQs\n",
        "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments) \n",
        "- Questions can be either autograded and manually graded.\n",
        "- The type of question and the points they carry are indicated in each question cell\n",
        "- An autograded question has 3 cells\n",
        "     - **Question cell** : Read only cell containing the question\n",
        "     - **Code Cell** : This is where you write the code\n",
        "     - **Grading cell** : This is where the grading occurs, and **you are required not to edit this cell**\n",
        "- Manually graded questions only have the question and code cells.\n",
        "- To avoid any ambiguity, each question also specifies what *value* the function must return. Note that these are dummy values and not the answers\n",
        "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
        "- Most assignments have bonus questions for extra credit, do try them out! \n",
        "- You can delete the `raise NotImplementedError()` for all manually graded questions.\n",
        "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to canvas. Do not delete any outputs from cells before submitting.\n",
        "- That's about it. Happy coding! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ccd093de0c01c601220c82809d785907",
          "grade": false,
          "grade_id": "cell-11a8a6cab098e8a1",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "uS-ZiJUd8Wfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c17ee3fa-f418-4ecb-ba7e-d627f9c324d9"
      },
      "source": [
        "import pandas as pd\n",
        "import collections\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "\n",
        "\n",
        "#DOWNLOADING DATASET\n",
        "!wget -nc http://people.ischool.berkeley.edu/~zp/course_datasets/yelp_reviewers.zip\n",
        "!unzip -u yelp_reviewers.zip\n",
        "print('Dataset Downloaded: yelp_reviewers.csv')\n",
        "df = pd.read_csv('yelp_reviewers.csv')\n",
        "df = df.sample(frac=0.3, random_state=42)\n",
        "print(df.dropna().describe())\n",
        "\n",
        "print('....SETUP COMPLETE....')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘yelp_reviewers.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  yelp_reviewers.zip\n",
            "Dataset Downloaded: yelp_reviewers.csv\n",
            "                q3           q4  ...        q16ab        q16ac\n",
            "count  7177.000000  7177.000000  ...  7177.000000  7177.000000\n",
            "mean      6.838651     5.281455  ...     1.127751     3.649254\n",
            "std       7.597977    16.208703  ...     4.652206     0.977100\n",
            "min       1.000000     1.000000  ...     0.000000     1.000000\n",
            "25%       3.000000     1.000000  ...     0.000000     3.200000\n",
            "50%       5.000000     2.000000  ...     0.500000     3.777778\n",
            "75%       9.000000     4.000000  ...     1.307692     4.333333\n",
            "max     252.000000   607.000000  ...   342.300000     5.000000\n",
            "\n",
            "[8 rows x 40 columns]\n",
            "....SETUP COMPLETE....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANCMpJ178foc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2fe4f1d0-25c1-4901-c7de-b4759ca84e8e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>q3</th>\n",
              "      <th>q4</th>\n",
              "      <th>q5</th>\n",
              "      <th>q6</th>\n",
              "      <th>q7</th>\n",
              "      <th>q8</th>\n",
              "      <th>q9</th>\n",
              "      <th>q10</th>\n",
              "      <th>q11</th>\n",
              "      <th>q12</th>\n",
              "      <th>q13</th>\n",
              "      <th>q14</th>\n",
              "      <th>q15</th>\n",
              "      <th>q16a</th>\n",
              "      <th>q16b</th>\n",
              "      <th>q16c</th>\n",
              "      <th>q16d</th>\n",
              "      <th>q16e</th>\n",
              "      <th>q16f</th>\n",
              "      <th>q16g</th>\n",
              "      <th>q16h</th>\n",
              "      <th>q16i</th>\n",
              "      <th>q16j</th>\n",
              "      <th>q16k</th>\n",
              "      <th>q16l</th>\n",
              "      <th>q16m</th>\n",
              "      <th>q16n</th>\n",
              "      <th>q16o</th>\n",
              "      <th>q16p</th>\n",
              "      <th>q16q</th>\n",
              "      <th>q16r</th>\n",
              "      <th>q16s</th>\n",
              "      <th>q16t</th>\n",
              "      <th>q16u</th>\n",
              "      <th>q16v</th>\n",
              "      <th>q16w</th>\n",
              "      <th>q16x</th>\n",
              "      <th>q16y</th>\n",
              "      <th>q16z</th>\n",
              "      <th>q16aa</th>\n",
              "      <th>q16ab</th>\n",
              "      <th>q16ac</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>129451</th>\n",
              "      <td>kIWQXgjmVdgEs9BOgr8G5A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>510.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.013725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>experienced</td>\n",
              "      <td>no</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116706</th>\n",
              "      <td>fXU_-5DBmNlGhI8fbX-2vQ</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>132.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>experienced</td>\n",
              "      <td>no</td>\n",
              "      <td>0.000</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144394</th>\n",
              "      <td>prF_lbKywPnZhNqvJOOaDw</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>1792.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>experienced</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>363.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24699</th>\n",
              "      <td>8GHUeOm807bI5Qh4X3CHBA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>283.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.017668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>experienced</td>\n",
              "      <td>no</td>\n",
              "      <td>0.000</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47453</th>\n",
              "      <td>Gd_IGX3BmRYbPD84ovLEoA</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2.08</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.08</td>\n",
              "      <td>18.18</td>\n",
              "      <td>9.09</td>\n",
              "      <td>72.73</td>\n",
              "      <td>10</td>\n",
              "      <td>663.38</td>\n",
              "      <td>4</td>\n",
              "      <td>0.353553</td>\n",
              "      <td>0.002073</td>\n",
              "      <td>4.875</td>\n",
              "      <td>0.022989</td>\n",
              "      <td>0.330719</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1.375</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.192489</td>\n",
              "      <td>5</td>\n",
              "      <td>experienced</td>\n",
              "      <td>no</td>\n",
              "      <td>0.375</td>\n",
              "      <td>8</td>\n",
              "      <td>39</td>\n",
              "      <td>0.001755</td>\n",
              "      <td>91.072917</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       user_id  q3  q4  q5  ...  q16z  q16aa  q16ab  q16ac\n",
              "129451  kIWQXgjmVdgEs9BOgr8G5A   1   0   0  ...     0      0    NaN  3.000\n",
              "116706  fXU_-5DBmNlGhI8fbX-2vQ   1   0   0  ...     0      0    0.0  1.000\n",
              "144394  prF_lbKywPnZhNqvJOOaDw   1   0   0  ...     0      0    NaN  3.000\n",
              "24699   8GHUeOm807bI5Qh4X3CHBA   1   0   0  ...     0      0    2.0  5.000\n",
              "47453   Gd_IGX3BmRYbPD84ovLEoA   8   2   1  ...     4      0    1.0  4.875\n",
              "\n",
              "[5 rows x 43 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "abffba52a1391fd598ceb32fa84a5960",
          "grade": false,
          "grade_id": "cell-91b1f66036bc756a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "mV9fSZv88Wfk",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9a3601934d89674b0f1ddb8953f392b8",
          "grade": false,
          "grade_id": "cell-3cb43492c95c0336",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "FyEW1omS8Wfk",
        "colab_type": "text"
      },
      "source": [
        "### Question 1 `(1 point)`\n",
        "What is the best choice of k according to the silhouette metric for clustering q4-q6? Only consider 2 <= k <= 8. \n",
        "\n",
        "\n",
        "**NOTE**: For features with high variance, empty clusters can occur. There are several ways of dealing with empty clusters. A common approach is to drop empty clusters, the prefered approach for this Lab is to treat the empty cluster as a “singleton” leaving it empty with a single point placeholder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "d870b56ad1274ceed7a8c1ad14120f4d",
          "grade": false,
          "grade_id": "cell-35daa961ef9ef163",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "SHN499lB8Wfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83dc90f1-524d-4e03-9e3d-0f8af3db9549"
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be an integer\n",
        "def q1(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q4','q5','q6']]\n",
        "    x = -1\n",
        "\n",
        "    for i in range(2,9):\n",
        "      kmeans = KMeans(n_clusters = i, random_state = 42)\n",
        "      kmeans.fit(q46)\n",
        "      score = silhouette_score(q46, kmeans.labels_)\n",
        "      \n",
        "      if score > x:\n",
        "        k = i\n",
        "        x = score\n",
        "    \n",
        "    return k\n",
        "\n",
        "\n",
        "print(q1(df))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9229f3626bea7238f91b319b76f8d6c1",
          "grade": false,
          "grade_id": "cell-1f4af152457c700f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "t1USbOiZ8Wfo",
        "colab_type": "text"
      },
      "source": [
        "What is the best choice of k? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "e686f8bb8933c06c0b80f1d3a0ab7c4c",
          "grade": true,
          "grade_id": "cell-75f42d06e03fe139",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "IiP-7-BI8Wfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55f10657-053e-44ad-e990-23102defdbd6"
      },
      "source": [
        "# YOUR ANSWER HERE\n",
        "2"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4d1db294cd60c6368ab7f1cc287ac861",
          "grade": false,
          "grade_id": "cell-3f1e7c00e311da4b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "nR7L0bqm8Wft",
        "colab_type": "text"
      },
      "source": [
        "### Question 2 `(1 point)`\n",
        "What is the best choice of k according to the silhouette metric for clustering q7-q10? Only consider 2 <= k <= 8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "9cf8b96c08dc833c7b88ee35362ed959",
          "grade": false,
          "grade_id": "cell-dc62c66cc9acf621",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "Jv9s-92L8Wft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f619635a-3d3a-42a3-f2bd-cbb3cabf7106"
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be an integer\n",
        "def q2(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q7','q8','q9','q10']].dropna()\n",
        "    x = -1\n",
        "\n",
        "    for i in range(2,9):\n",
        "      kmeans = KMeans(n_clusters = i, random_state = 42)\n",
        "      kmeans.fit(q46)\n",
        "      score = silhouette_score(q46, kmeans.labels_)\n",
        "      \n",
        "      if score > x:\n",
        "        k = i\n",
        "        x = score\n",
        "    \n",
        "    return k\n",
        "\n",
        "print(q2(df))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "13a5d949504f1ed6dbf3bf474d135175",
          "grade": false,
          "grade_id": "cell-a798fe1067889c85",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ohkPzjsf8Wfz",
        "colab_type": "text"
      },
      "source": [
        "What is the best choice of k? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "39518f72ac99d22c2be6e053d683ecb3",
          "grade": true,
          "grade_id": "cell-b9c0fc321a251e1e",
          "locked": false,
          "points": 0.5,
          "schema_version": 1,
          "solution": true
        },
        "id": "WwlzPYjj8Wf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80be69a0-7004-44a0-b152-f3f27c9329a1"
      },
      "source": [
        "# YOUR ANSWER HERE\n",
        "2"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "685cbed1a7666b907cfd74876798b246",
          "grade": false,
          "grade_id": "cell-abc5d1274688008b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QW6AW5SN8Wf3",
        "colab_type": "text"
      },
      "source": [
        "### Question 3 `(1 point)`\n",
        "What is the best choice of k according to the silhouette metric for clustering q11-q13? Only consider 2 <= k <= 8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "79b98812400934790474017de005b61b",
          "grade": false,
          "grade_id": "cell-fa2944f22a609780",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "FU0QGeDx8Wf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e6e6285-9340-4ec1-ab2f-5cadaba29d57"
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be an integer\n",
        "def q3(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q11','q12','q13']].dropna()\n",
        "    x = -1\n",
        "\n",
        "    for i in range(2,9):\n",
        "      kmeans = KMeans(n_clusters = i, random_state = 42)\n",
        "      kmeans.fit(q46)\n",
        "      score = silhouette_score(q46, kmeans.labels_)\n",
        "      \n",
        "      if score > x:\n",
        "        k = i\n",
        "        x = score\n",
        "    \n",
        "    return k\n",
        "print(q3(df))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7f1e4d9e7bc46ed5b72756983c3ea7d1",
          "grade": false,
          "grade_id": "cell-ffde459d3d7f30d4",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Y-5NyKXZ8Wf_",
        "colab_type": "text"
      },
      "source": [
        "What is the best choice of k?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "286a814a2fc12cff437655784716f2d7",
          "grade": true,
          "grade_id": "cell-dd60c729c46b5610",
          "locked": false,
          "points": 0.5,
          "schema_version": 1,
          "solution": true
        },
        "id": "AZfZebXo8WgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57ba0345-0955-49d5-c0ce-cc9cfc52cc8d"
      },
      "source": [
        "# YOUR ANSWER HERE\n",
        "8"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a18ebc832af60a47193b79496235a06c",
          "grade": false,
          "grade_id": "cell-3bf4719c7aa218c6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "aQMzO6nF8WgJ",
        "colab_type": "text"
      },
      "source": [
        "### Question 4 `(1 point)`\n",
        "Consider the best clustering (i.e., best value of K) from Question 3 and list the number of data points in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "cc9c33b42265e3a41d8fefb18770a4e8",
          "grade": false,
          "grade_id": "cell-24fde636c2f83a67",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "ztW4Dgbc8WgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be an dictionary. Eg : {0:1000,1:500,2:1460}\n",
        "def q4(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q11','q12','q13']].dropna()\n",
        "    kmeans = KMeans(n_clusters = 8, random_state = 42)\n",
        "    kmeans.fit(q46)\n",
        "    labels = kmeans.labels_.tolist()\n",
        "\n",
        "    d = {}\n",
        "    for i in range(0,8):\n",
        "      d[i] = labels.count(i)\n",
        "    \n",
        "    return d"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "99637ce263f2207d1701716f5f1f44ca",
          "grade": true,
          "grade_id": "cell-2deca552fa9f803f",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "iIUdLPIw8WgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f428274b-4ead-407f-89e9-35e46876ac32"
      },
      "source": [
        "#This is an autograded cell, do not edit\n",
        "print(q4(df))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 3307, 1: 1632, 2: 2862, 3: 9848, 4: 5723, 5: 3405, 6: 1192, 7: 2140}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f455a94d03bf20a31ce26a2da672ee98",
          "grade": false,
          "grade_id": "cell-4277f89074807c16",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "xgii61fI8WgT",
        "colab_type": "text"
      },
      "source": [
        "### Question 5 `(1 point)`\n",
        "Consider the best cluster from Question 3. Were there clusters that represented very funny but useless reviewers (check column definitions for columns corresponding to funny, useless etc)?  If so, print the center of that cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "d2664de57a82a4d02c7d529617a1450c",
          "grade": false,
          "grade_id": "cell-550e8e6942843343",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "_XzB8j6f8WgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be an Array. Eg : [10,30,54]\n",
        "def q5(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q11','q12','q13']].dropna()\n",
        "    kmeans = KMeans(n_clusters = 8, random_state = 42)\n",
        "    kmeans.fit(q46)\n",
        "    return kmeans.cluster_centers_[1]"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "36e1fb3627b616460376cfe2db01762c",
          "grade": true,
          "grade_id": "cell-5c9ad8f64f9e3cb9",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "g22ke0I48WgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc319df6-2601-4398-eb9e-419c88a6900e"
      },
      "source": [
        "#This is an autograded cell, do not edit\n",
        "print(np.round_(q5(df), decimals=1, out=None))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.1 98.3  0.6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "423fac1c99ce7c9090dd9e96e6778777",
          "grade": false,
          "grade_id": "cell-303792a4ac61cb3a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "U2yg2Z2_8Wgd",
        "colab_type": "text"
      },
      "source": [
        "### Question 6 `(1 point)`\n",
        "Consider the best clustering from Question 3. What was the centroid of the cluster that represented relatively equal strength in all voting categories?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "9b6ebc1ed5ed8d8042dcf7cd49952b57",
          "grade": false,
          "grade_id": "cell-391c7439f978dff8",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "94isPDi08Wgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "def q6(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q11','q12','q13']].dropna()\n",
        "    kmeans = KMeans(n_clusters = 8, random_state = 42)\n",
        "    kmeans.fit(q46)\n",
        "    labels = kmeans.labels_.tolist()\n",
        "\n",
        "    return labels.count(4)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "cfcf6b7a02a8426368b49ab70898113b",
          "grade": true,
          "grade_id": "cell-4a75c628cdd62ed3",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "GKePHYay8Wgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aae539b2-7880-430e-801b-81b5e918e4d3"
      },
      "source": [
        "#This is an autograded cell, do not edit\n",
        "print(q6(df))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7277b47e7131491c1b5bc8487bc7f848",
          "grade": false,
          "grade_id": "cell-b29200abdbf3f648",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "BlCXYH7J8Wgp",
        "colab_type": "text"
      },
      "source": [
        "### Question 7 `(1 point)`\n",
        "Cluster the dataset using $k = 5$ and using features q7-q15 (refer to the column descriptions if needed).\n",
        "What is the silhouette metric for this clustering?\n",
        "For a more in-depth understanding of cluster analysis with silhouette, look [here](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "aadc8b4d3daea84bcdf7326f7d9e1e48",
          "grade": false,
          "grade_id": "cell-692872a9776a2f81",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "P5AW-1Hj8Wgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be a float\n",
        "def q7(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    q46 = df[['q7','q8','q9','q10','q11','q12','q13','q14','q15']].dropna()\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "    kmeans.fit(q46)\n",
        "    return silhouette_score(q46, kmeans.labels_)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7c847dc80333efefec63b12bce9a3c23",
          "grade": true,
          "grade_id": "cell-d5a3ed8462b9b40b",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "Kx23kyP18Wgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "851de6dd-b1da-4bd6-9215-0fe2d13bad49"
      },
      "source": [
        "#This is an autograded cell, do not edit\n",
        "print(q7(df))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5481158706623568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b5206e977bdec3a2a2da9a55d42539e1",
          "grade": false,
          "grade_id": "cell-bb20d152047de4c0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ghXtWRlm8Wg1",
        "colab_type": "text"
      },
      "source": [
        "### Question 8 `(1 point)`\n",
        "Cluster the dataset using $k = 5$ and using features q7-q15 (refer to the column descriptions if needed).\n",
        "\n",
        "What was the average q3 among the points in each of the clusters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "cec8fcc62994a8c42d2a828240cf8d70",
          "grade": false,
          "grade_id": "cell-ce75d2c2b37a5939",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "7VLNa7ZT8Wg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make sure you return the answer value in this function\n",
        "#The return value must be an Array. Eg : [10,30,54]\n",
        "def q8(df):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    df1 = df[['q3','q7','q8','q9','q10','q11','q12','q13','q14','q15']].dropna()\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "    kmeans.fit(df1)\n",
        "    df1['label']= kmeans.labels_\n",
        "    return df1.groupby('label').mean()['q3'].tolist()"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "8fcac0a1587052a68abfd2dc22e6a444",
          "grade": true,
          "grade_id": "cell-125a523ba764c027",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "uU1zA9hQ8Wg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9655d77c-4cd2-45c5-c782-6e0086fc8eef"
      },
      "source": [
        "#This is an autograded cell, do not edit\n",
        "print(np.round_(q8(df), decimals=1, out=None))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7.3 4.9 6.6 2.4 6.9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "539014b1c77f0d5159b9158216999ffa",
          "grade": false,
          "grade_id": "cell-32dc52f985a4469b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ImMBccCv8WhE",
        "colab_type": "text"
      },
      "source": [
        "### Question 9 `(2 points)`\n",
        "**This question will be manually graded.**\n",
        "\n",
        "Cluster the dataset using all features in the dataset\n",
        "\n",
        "We can drop features with high incidents of -Inf / blank / or NaN values). It is suggested that you perform some form of normalization on these question 16 features so as not to over bias the clustering towards the larger magnitude features. Let's do that now.\n",
        "\n",
        "#### Data Cleansing and Normalization ####\n",
        "Check how many null values there are in each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "26c5eee0748fe77d6f219f2f654adc69",
          "grade": false,
          "grade_id": "cell-00e25d9828db774a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "vdt07lvl8WhH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "b86f3a6c-213d-4e9e-cea6-adea4e57e452"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df.isnull().sum()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id        0\n",
              "q3             0\n",
              "q4             0\n",
              "q5             0\n",
              "q6             0\n",
              "q7             0\n",
              "q8         35280\n",
              "q9         36743\n",
              "q10        24338\n",
              "q11        21383\n",
              "q12        21383\n",
              "q13        21383\n",
              "q14            0\n",
              "q15            0\n",
              "q16a           0\n",
              "q16b           0\n",
              "q16c           0\n",
              "q16d           0\n",
              "q16e           0\n",
              "q16f           0\n",
              "q16g           0\n",
              "q16h           0\n",
              "q16i           0\n",
              "q16j           0\n",
              "q16k           0\n",
              "q16l           0\n",
              "q16m           0\n",
              "q16n           0\n",
              "q16o           0\n",
              "q16p           0\n",
              "q16q           0\n",
              "q16r           0\n",
              "q16s           0\n",
              "q16t           0\n",
              "q16u           0\n",
              "q16v           0\n",
              "q16w           0\n",
              "q16x           0\n",
              "q16y           0\n",
              "q16z           0\n",
              "q16aa          0\n",
              "q16ab      14469\n",
              "q16ac          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "059796c35a25a2239b6af643d573077c",
          "grade": false,
          "grade_id": "cell-dda1709aadca4b74",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "yzAo6QRS8WhO",
        "colab_type": "text"
      },
      "source": [
        "It looks like q8 - q13 and q16ab have a lot of null values. Let's see what the impact is of removing the two columns with the most null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c9201f034d5527471e11c4bdf4259a06",
          "grade": false,
          "grade_id": "cell-e67e9b14f016567d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "pSrZ9i3g8WhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "167cf231-d02c-4b81-ac18-a3d8f5173d21"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df1 = df.drop(columns=['q8','q9'])\n",
        "print(len(df.dropna()))\n",
        "print(len(df1.dropna()))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7177\n",
            "19582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "55ec19beab75bcb01d51763aa77b7c7d",
          "grade": false,
          "grade_id": "cell-0832f08869a19534",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "gQbRuq_Z8Whb",
        "colab_type": "text"
      },
      "source": [
        "By removing two features, we effectively have double the number of rows remaining. That's pretty good.  \n",
        "Now, let's preprocess categorical variables into dummy values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9520a1834882784cba16fa1e635aeb9e",
          "grade": false,
          "grade_id": "cell-46dc2129f7ac4991",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "xnXUaCHl8Whc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d44abf57-fdeb-4628-ed0e-2d6e8d55d711"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df1 = pd.get_dummies(data=df1,columns=['q16s','q16t'])\n",
        "df1 = df1.drop(columns=['user_id'])\n",
        "df1.head()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q3</th>\n",
              "      <th>q4</th>\n",
              "      <th>q5</th>\n",
              "      <th>q6</th>\n",
              "      <th>q7</th>\n",
              "      <th>q10</th>\n",
              "      <th>q11</th>\n",
              "      <th>q12</th>\n",
              "      <th>q13</th>\n",
              "      <th>q14</th>\n",
              "      <th>q15</th>\n",
              "      <th>q16a</th>\n",
              "      <th>q16b</th>\n",
              "      <th>q16c</th>\n",
              "      <th>q16d</th>\n",
              "      <th>q16e</th>\n",
              "      <th>q16f</th>\n",
              "      <th>q16g</th>\n",
              "      <th>q16h</th>\n",
              "      <th>q16i</th>\n",
              "      <th>q16j</th>\n",
              "      <th>q16k</th>\n",
              "      <th>q16l</th>\n",
              "      <th>q16m</th>\n",
              "      <th>q16n</th>\n",
              "      <th>q16o</th>\n",
              "      <th>q16p</th>\n",
              "      <th>q16q</th>\n",
              "      <th>q16r</th>\n",
              "      <th>q16u</th>\n",
              "      <th>q16v</th>\n",
              "      <th>q16w</th>\n",
              "      <th>q16x</th>\n",
              "      <th>q16y</th>\n",
              "      <th>q16z</th>\n",
              "      <th>q16aa</th>\n",
              "      <th>q16ab</th>\n",
              "      <th>q16ac</th>\n",
              "      <th>q16s_experienced</th>\n",
              "      <th>q16s_freshman</th>\n",
              "      <th>q16t_no</th>\n",
              "      <th>q16t_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>129451</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>510.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.013725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116706</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>132.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144394</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>1792.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>2.000</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>363.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24699</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>283.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.017668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47453</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2.08</td>\n",
              "      <td>2.08</td>\n",
              "      <td>18.18</td>\n",
              "      <td>9.09</td>\n",
              "      <td>72.73</td>\n",
              "      <td>10</td>\n",
              "      <td>663.38</td>\n",
              "      <td>4</td>\n",
              "      <td>0.353553</td>\n",
              "      <td>0.002073</td>\n",
              "      <td>4.875</td>\n",
              "      <td>0.022989</td>\n",
              "      <td>0.330719</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1.375</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.192489</td>\n",
              "      <td>5</td>\n",
              "      <td>0.375</td>\n",
              "      <td>8</td>\n",
              "      <td>39</td>\n",
              "      <td>0.001755</td>\n",
              "      <td>91.072917</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.875</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        q3  q4  q5  q6  ...  q16s_experienced  q16s_freshman  q16t_no  q16t_yes\n",
              "129451   1   0   0   0  ...                 1              0        1         0\n",
              "116706   1   0   0   0  ...                 1              0        1         0\n",
              "144394   1   0   0   0  ...                 1              0        1         0\n",
              "24699    1   0   0   0  ...                 1              0        1         0\n",
              "47453    8   2   1   8  ...                 1              0        1         0\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7409a97cd6cc5a2203cb5953fd78951e",
          "grade": false,
          "grade_id": "cell-0bf07ed81b15a7c6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "AGnnilDI8Whl",
        "colab_type": "text"
      },
      "source": [
        "Now, normalize the remaining values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d415896af702471cbf3bad5e3bbf2298",
          "grade": false,
          "grade_id": "cell-d0c0fa3af31b680b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "-tYTGviT8Whm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "6777a098-5fe7-4d62-8900-0923cc7c17d6"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df1 = df1.dropna()\n",
        "df2 = pd.DataFrame(list(map(np.ravel, normalize(df1))))\n",
        "df2.columns = df1.columns\n",
        "df2.head()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q3</th>\n",
              "      <th>q4</th>\n",
              "      <th>q5</th>\n",
              "      <th>q6</th>\n",
              "      <th>q7</th>\n",
              "      <th>q10</th>\n",
              "      <th>q11</th>\n",
              "      <th>q12</th>\n",
              "      <th>q13</th>\n",
              "      <th>q14</th>\n",
              "      <th>q15</th>\n",
              "      <th>q16a</th>\n",
              "      <th>q16b</th>\n",
              "      <th>q16c</th>\n",
              "      <th>q16d</th>\n",
              "      <th>q16e</th>\n",
              "      <th>q16f</th>\n",
              "      <th>q16g</th>\n",
              "      <th>q16h</th>\n",
              "      <th>q16i</th>\n",
              "      <th>q16j</th>\n",
              "      <th>q16k</th>\n",
              "      <th>q16l</th>\n",
              "      <th>q16m</th>\n",
              "      <th>q16n</th>\n",
              "      <th>q16o</th>\n",
              "      <th>q16p</th>\n",
              "      <th>q16q</th>\n",
              "      <th>q16r</th>\n",
              "      <th>q16u</th>\n",
              "      <th>q16v</th>\n",
              "      <th>q16w</th>\n",
              "      <th>q16x</th>\n",
              "      <th>q16y</th>\n",
              "      <th>q16z</th>\n",
              "      <th>q16aa</th>\n",
              "      <th>q16ab</th>\n",
              "      <th>q16ac</th>\n",
              "      <th>q16s_experienced</th>\n",
              "      <th>q16s_freshman</th>\n",
              "      <th>q16t_no</th>\n",
              "      <th>q16t_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011846</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.011846</td>\n",
              "      <td>0.003080</td>\n",
              "      <td>0.003080</td>\n",
              "      <td>0.026920</td>\n",
              "      <td>0.013460</td>\n",
              "      <td>0.107696</td>\n",
              "      <td>0.014808</td>\n",
              "      <td>0.982306</td>\n",
              "      <td>0.005923</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>3.069221e-06</td>\n",
              "      <td>0.007219</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.008885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002036</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006663</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.001111</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.000285</td>\n",
              "      <td>0.007404</td>\n",
              "      <td>0.000555</td>\n",
              "      <td>0.011846</td>\n",
              "      <td>0.057750</td>\n",
              "      <td>2.598805e-06</td>\n",
              "      <td>0.134857</td>\n",
              "      <td>0.005923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.007219</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.001281</td>\n",
              "      <td>0.046410</td>\n",
              "      <td>0.046410</td>\n",
              "      <td>0.092820</td>\n",
              "      <td>0.018564</td>\n",
              "      <td>0.988535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>6.972409e-06</td>\n",
              "      <td>0.005569</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010210</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.040841</td>\n",
              "      <td>0.011138</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.086323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005569</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049250</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>0.993862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.440526e-07</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000985</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.018222</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>2.450238e-07</td>\n",
              "      <td>0.097022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002462</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003793</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003034</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075862</td>\n",
              "      <td>0.004552</td>\n",
              "      <td>0.988789</td>\n",
              "      <td>0.000759</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>4.656268e-07</td>\n",
              "      <td>0.002731</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.001135</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.001517</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009710</td>\n",
              "      <td>0.000759</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.003793</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.010621</td>\n",
              "      <td>0.013655</td>\n",
              "      <td>1.197058e-06</td>\n",
              "      <td>0.126690</td>\n",
              "      <td>0.000759</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000948</td>\n",
              "      <td>0.002731</td>\n",
              "      <td>0.000759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000759</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.007589</td>\n",
              "      <td>0.007589</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.012333</td>\n",
              "      <td>0.001973</td>\n",
              "      <td>0.002429</td>\n",
              "      <td>0.029191</td>\n",
              "      <td>0.018243</td>\n",
              "      <td>0.047434</td>\n",
              "      <td>0.008538</td>\n",
              "      <td>0.993732</td>\n",
              "      <td>0.001897</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>2.943367e-06</td>\n",
              "      <td>0.003558</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.001137</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>0.007589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005218</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>0.002846</td>\n",
              "      <td>0.028460</td>\n",
              "      <td>9.355186e-06</td>\n",
              "      <td>0.086853</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>0.012333</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>0.003558</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         q3        q4        q5  ...  q16s_freshman   q16t_no  q16t_yes\n",
              "0  0.011846  0.002962  0.001481  ...            0.0  0.001481       0.0\n",
              "1  0.003713  0.001856  0.001856  ...            0.0  0.001856       0.0\n",
              "2  0.000492  0.000000  0.000000  ...            0.0  0.000492       0.0\n",
              "3  0.003793  0.000000  0.000000  ...            0.0  0.000759       0.0\n",
              "4  0.007589  0.007589  0.004743  ...            0.0  0.000949       0.0\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "26e9bec01f855d44456f65879afa7ccf",
          "grade": false,
          "grade_id": "cell-be1b2a4ecbcb5558",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "jSJjHlsc8Wht",
        "colab_type": "text"
      },
      "source": [
        "Using the the `sum of within cluster variance` metric with the elbow method what was the best k?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "3971d6b7067c2e2b586a79b0fca34252",
          "grade": true,
          "grade_id": "cell-f49f54902337159c",
          "locked": false,
          "points": 2,
          "schema_version": 1,
          "solution": true
        },
        "id": "HoZOPumL8Whv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f29c7521-3484-4b50-907e-359040429a3b"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "sse = []\n",
        "for i in range(1,9):\n",
        "    model = KMeans(n_clusters = i).fit(df1)\n",
        "    sse.append(sum(np.min(cdist(df1, model.cluster_centers_, 'euclidean'), axis=1)) / df1.shape[0])\n",
        "\n",
        "plt.plot(range(1,9), sse, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Distortion')\n",
        "plt.title('The Elbow Method showing the optimal k')\n",
        "plt.show()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXDNZ2CatRtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "87e1d4d9-a255-42d6-e6f2-9981f76a45d7"
      },
      "source": [
        "diffs = []\n",
        "for i in range(0,7):\n",
        "  diffs.append(sse[i] - sse[i+1])\n",
        "\n",
        "print(diffs)\n",
        "print(\"optimal k = 2\")"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[64.26874916786508, 38.90623393414296, 23.67044730880974, 17.259028676885947, 15.093700170918169, 9.098647242258977]\n",
            "optimal k = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "78e8416b2c9c63fb2e91cc747a982eb9",
          "grade": false,
          "grade_id": "cell-ed56b09f2baf02c7",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "_-cRpVgA8Wh2",
        "colab_type": "text"
      },
      "source": [
        "### Question 10 `(1 points)`\n",
        "**This question will be manually graded.**\n",
        "\n",
        "For this question please come up with your own question about this dataset and using a clustering technique as part of your method of answering it. Describe in short the question, and how clustering can answer that question.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "5ec519964252120ba10b8ea5633da3d3",
          "grade": true,
          "grade_id": "cell-01090109d82adc22",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "vGcMVdVM8Wh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "029894cd-0690-4958-911d-e702937e80dd"
      },
      "source": [
        "# Is there an amount of clusters that we can make where we can see a significant \n",
        "# part of that cluster that uses vulgar language (q16i) using features that analyze language?\n",
        "df3 = df[['q16g','q16h','q16i','q16k','q16n','q16p','q16u']]\n",
        "\n",
        "f1 = []\n",
        "for i in range(1, 50):\n",
        "  kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "  kmeans.fit(df3)\n",
        "  clusters = kmeans.cluster_centers_\n",
        "\n",
        "  f = []\n",
        "  for i in range(0,len(clusters)):\n",
        "    f.append(clusters[i][2])\n",
        "  \n",
        "  f1.append(max(f))\n",
        "\n",
        "f1"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.007768197001476487,\n",
              " 0.02184678124089793,\n",
              " 0.027597402597402773,\n",
              " 0.023929471032745807,\n",
              " 0.04034582132564857,\n",
              " 0.04281345565749251,\n",
              " 0.07236842105263158,\n",
              " 0.06878306878306893,\n",
              " 0.05813953488372088,\n",
              " 0.057142857142857086,\n",
              " 0.05813953488372088,\n",
              " 0.04838709677419349,\n",
              " 0.0461538461538461,\n",
              " 0.0491803278688524,\n",
              " 0.06557377049180323,\n",
              " 0.051724137931034427,\n",
              " 0.06060606060606055,\n",
              " 0.051724137931034427,\n",
              " 0.07246376811594199,\n",
              " 0.07936507936507932,\n",
              " 0.06153846153846152,\n",
              " 0.07777777777777774,\n",
              " 0.06349206349206347,\n",
              " 0.0642201834862385,\n",
              " 0.0754716981132075,\n",
              " 0.06818181818181815,\n",
              " 0.06779661016949151,\n",
              " 0.0754716981132075,\n",
              " 0.07142857142857142,\n",
              " 0.08888888888888884,\n",
              " 0.0689655172413793,\n",
              " 0.07272727272727272,\n",
              " 0.07999999999999999,\n",
              " 0.10526315789473684,\n",
              " 0.10526315789473684,\n",
              " 0.08695652173913047,\n",
              " 0.08695652173913047,\n",
              " 0.08695652173913047,\n",
              " 0.08695652173913047,\n",
              " 0.08695652173913047,\n",
              " 0.08695652173913039,\n",
              " 0.09090909090909087,\n",
              " 0.09302325581395346,\n",
              " 0.08695652173913039,\n",
              " 0.0789473684210526,\n",
              " 0.0789473684210526,\n",
              " 0.07999999999999996,\n",
              " 0.07999999999999996,\n",
              " 0.09090909090909087]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC5uxC7F5Ipm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75f35da0-1dbc-48d7-9682-ae36ee2e97fa"
      },
      "source": [
        "print(\"Verdict: inconclusive\")"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdict: inconclusive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "47c18987b74081b9f0e201d36229f33d",
          "grade": false,
          "grade_id": "cell-b549ed2cba475bb7",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Ylv6UWqm8WiC",
        "colab_type": "text"
      },
      "source": [
        "## Bonus question (`2 Points`) - Reviewer overlap:\n",
        "- Download last week's dataset\n",
        "- Aggregate cool, funny and useful votes for each business id\n",
        "- You may transform the aggregations (take %, log, or leave it as it is)\n",
        "- Cluster this dataframe (you can choose k). Do you find any meaningful/interesting clusters?\n",
        "- Assign the cluster label to each business id\n",
        "- Merge this with users to show what clusters the reviewers have reviewed. (You may need to use the pivot function) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "b07907c97fe5a173c8ed578ba3d2876b",
          "grade": true,
          "grade_id": "cell-33aa50b382e692ca",
          "locked": false,
          "points": 2,
          "schema_version": 1,
          "solution": true
        },
        "id": "j319ReI98WiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
